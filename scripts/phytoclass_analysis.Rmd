---
title: "R Notebook"
output: html_notebook
---

```{r}
#Loading packages
library(phytoclass)
library(readxl)
library(dplyr)
library(tidyr)
library(lubridate)
library(ggplot2)
library(forcats)
library(here)
library(purrr)
library(hakaiApi)

# Source functions
source(here("functions", "functions.R"))
```
---
Download data and wrangling
---
```{r}
# Initialize the client
client <- Client$new()
```
```{r}
#Setting up Query
endpoint <- "/eims/views/output/hplc"
filter <- "site_id=QU39&"
chl_url <- paste0("https://hecate.hakai.org/api", endpoint,"?limit=-1&", filter)
data <- client$get(chl_url)
```

```{r}
#Wrangling the data to prepare it for analysis

#Select the data and pigments that will be analyzed with phytoclass
# rename columns for analysis and drop any rows with NAs
h <- data %>%
  filter(line_out_depth == 5 & site_id == "QU39" & analyzing_lab == "USC") %>%
  # filter(date < "2019-01-01") %>% 
  select(date,
         site_id,
         depth = line_out_depth,
         C12 = chl_c1_c2,
         Per = peri,
         X19but = `_19_but`,
         Fuco = fuco,
         Pra = prasinoxanthin,
         X19hex = `_19_hex`,
         Allo = alloxanthin,
         Zea = zeaxanthin,
         Lut = lutein,
         Chl_b = chl_b,
         Tchla = all_chl_a) %>% 
  drop_na() %>% 
  # Calculate daily averages across all pigments - need here as can cause errors with clustering
  group_by(date, site_id, depth) %>%
  summarise(across(C12:Tchla, ~ mean(.x, na.rm = TRUE)), .groups = "drop") %>%
  # Add row numbers and create ID after averaging
  group_by(date) %>% 
  mutate(n = row_number()) %>% 
  ungroup() %>% 
  unite(id, c(date, site_id, depth, n), sep = "-", remove = FALSE)   #Create unique id for later joining


h <- as.data.frame(h)

#Setting ID for rownames to associate metadata at later point.
rownames(h) <- h$id

#Creating data matrix for analysis
data_matrix <- h %>% 
  select(C12:Tchla)

#Creating metadata column to join back with data later.
metadata <- h %>% 
  select(id:depth) %>% 
  rename(sample_id = id)
```

```{r}
cryp_allo <- data %>% 
  mutate(allo_rat = alloxanthin/all_chl_a) %>% 
  summarise(min = min(allo_rat, na.rm = T),
            max = max(allo_rat, na.rm = T),
            mean = mean(allo_rat, na.rm = T),
            geometric_mean = exp(mean(log(allo_rat[allo_rat > 0]),
                                       na.rm = TRUE)),
            multiplier = 100*(max/geometric_mean))

hap_hex <- data %>% 
  mutate(hex_rat = `_19_hex`/all_chl_a) %>% 
  summarise(min = min(hex_rat, na.rm = T),
            max = max(hex_rat, na.rm = T),
            mean = mean(hex_rat, na.rm = T),
            geometric_mean = exp(mean(log(hex_rat[hex_rat > 0]),
                                       na.rm = TRUE)),
            multiplier = 100*(max/geometric_mean))
```

```{r}
data %>% 
  ggplot(aes(x = chl_c1_c2, y = fuco, colour = all_chl_a)) +
  geom_point() +
  scale_color_viridis_b()

data %>% 
  ggplot(aes(x = `_19_hex`, y = `_19_but`, colour = all_chl_a)) +
  geom_point() +
  scale_color_viridis_b()

data %>% 
  ggplot(aes(x = prasinoxanthin, y = chl_b, colour = all_chl_a)) +
  geom_point() +
  scale_color_viridis_b()

data %>% 
  ggplot(aes(x = `_19_hex`, y = chl_c1_c2, colour = all_chl_a)) +
  geom_point() +
  scale_color_viridis_b()

#Should try to re-assess this using microscopy
```

```{r}
#running functions to extract standardized input matrices for analysis - Set up so everything is correct; however, phytoclass is very finicky and any small discrepancies between pigment or group names will throw it off. Min Max ratios also have a difference threshold, which is build into the error checking.
results <- create_complete_phytoclass_setup("min_chem_100.csv",
                                            "max_chem_100.csv")

min_max_matrix <- results$Min_max           # For phytoclass analysis
pigment_matrix <- results$pigment_matrix    # Binary matrix (1/0)
```

```{r}
#Test to see if data works
test <- simulated_annealing(
    S = data_matrix,
    F = pigment_matrix,
    user_defined_min_max = min_max_matrix,
    do_matrix_checks = T,
    niter = 1, #Kept at one for initial analysis - recommended to be 500.
    step = 0.09,
    weight.upper.bound = 30,
    verbose = T
  )

test$`F matrix`
test$Figure
```


```{r}
#Performs recommended pre-analysis clustering to group data with similar pigment ratios

# Get clusters and remove Clust column
clusters <- lapply(Cluster(data_matrix, min_cluster_size = 14)$cluster.list, #14 is default, but seems crazy
                   function(x) { x$Clust <- NULL; x })

# Add the full dataset as the first element so unclustered results can be compared to clustered.
full_data <- data_matrix
full_data$Clust <- NULL  # Remove cluster column if it exists
clusters <- c(list(full_data), clusters)

# Create names for each cluster in list including full dataset
names(clusters) <- c("full_dataset", paste0("clust", seq_along(clusters[-1])))
list2env(clusters, envir = .GlobalEnv)

# Now you have full_dataset, clust1, clust2, clust3, etc. as separate dataframes
```

```{r}
# Create seasonal subsets based on astronomical seasons
# Assumes you have data_matrix (pigments only) and metadata (with sample_id and date)
create_seasonal_subsets <- function(data_matrix, metadata, sample_id_col = "sample_id", date_col = "date") {
  
  # Ensure metadata date column is Date class
  if(!inherits(metadata[[date_col]], "Date")) {
    metadata[[date_col]] <- as.Date(metadata[[date_col]])
  }
  
  # Function to determine astronomical season for a given date
  get_astronomical_season <- function(date) {
    year <- year(date)
    month <- month(date)
    day <- day(date)
    
    # Approximate dates for astronomical seasons (Northern Hemisphere)
    # Spring Equinox: ~March 20-21
    # Summer Solstice: ~June 20-21  
    # Autumn Equinox: ~September 22-23
    # Winter Solstice: ~December 21-22
    
    if ((month == 3 & day >= 20) | month %in% c(4, 5) | (month == 6 & day < 21)) {
      return("spring")
    } else if ((month == 6 & day >= 21) | month %in% c(7, 8) | (month == 9 & day < 22)) {
      return("summer") 
    } else if ((month == 9 & day >= 22) | month %in% c(10, 11) | (month == 12 & day < 21)) {
      return("autumn")
    } else {
      return("winter")
    }
  }
  
  # Add season classification to metadata
  metadata$season <- sapply(metadata[[date_col]], get_astronomical_season)
  
  # Match data_matrix rownames to metadata sample_id
  # Assuming rownames(data_matrix) correspond to metadata sample_id
  sample_seasons <- metadata$season[match(rownames(data_matrix), metadata[[sample_id_col]])]
  
  # Create seasonal subsets of data_matrix
  spring_data <- data_matrix[sample_seasons == "spring" & !is.na(sample_seasons), , drop = FALSE]
  summer_data <- data_matrix[sample_seasons == "summer" & !is.na(sample_seasons), , drop = FALSE]
  autumn_data <- data_matrix[sample_seasons == "autumn" & !is.na(sample_seasons), , drop = FALSE]
  winter_data <- data_matrix[sample_seasons == "winter" & !is.na(sample_seasons), , drop = FALSE]
  
  # Create list similar to clustering approach
  seasons <- list(
    full_dataset = data_matrix,
    spring = spring_data,
    summer = summer_data, 
    autumn = autumn_data,
    winter = winter_data
  )
  
  return(seasons)
}

# Apply seasonal subsetting
# Adjust column names to match your actual metadata structure
seasons <- create_seasonal_subsets(data_matrix, metadata, 
                                 sample_id_col = "sample_id", 
                                 date_col = "date")

# Add to global environment (similar to your clustering approach)
list2env(seasons, envir = .GlobalEnv)

# Remove full dataset if desired (similar to your clustering approach)
seasons[[1]] <- NULL

# Set seed once for reproducibility  
set.seed(7683)

# Run phytoclass analysis on full dataset and all seasons independently
results_list <- list()
for(i in seq_along(seasons)) {
  season_name <- names(seasons)[i]
  cat("Processing", season_name, "(", i, "of", length(seasons), ")\n")
  
  # Check if season has enough data (similar to min_cluster_size)
  if(nrow(seasons[[i]]) < 14) {
    cat("Warning:", season_name, "has only", nrow(seasons[[i]]), "samples - consider combining seasons or using full dataset\n")
    next
  }
  
  results_list[[i]] <- simulated_annealing(
    S = seasons[[i]], 
    F = pigment_matrix,
    user_defined_min_max = min_max_matrix, # You'll want season-specific matrices here eventually
    do_matrix_checks = T,
    niter = 500,
    step = 0.09,
    weight.upper.bound = 30,
    verbose = F
  )
  
  names(results_list)[i] <- season_name
}

# Remove NULL elements (seasons with insufficient data)
results_list <- results_list[!sapply(results_list, is.null)]

# Print summary of seasonal data sizes
cat("\nSeasonal data summary:\n")
for(season_name in names(seasons)) {
  cat(season_name, ":", nrow(seasons[[season_name]]), "samples\n")
}
```





```{r}
#If turned on, this will remove the full dataset from the list - likely not necessary to analyze the full dataset each time, just useful to assess the effect of running the analysis on the individual clusters.
clusters[[1]] <- NULL
```



```{r}
# Set seed once for reproducibility
set.seed(7683)

# Run phytoclass analysis on full dataset and all clusters independently
results_list <- list()
for(i in seq_along(clusters)) {
  dataset_name <- names(clusters)[i]
  cat("Processing", dataset_name, "(", i, "of", length(clusters), ")\n")
  
  results_list[[i]] <- simulated_annealing(
    S = clusters[[i]], 
    F = pigment_matrix,
    user_defined_min_max = min_max_matrix,
    do_matrix_checks = T,
    niter = 500, #Kept at one for initial analysis - recommended to be 500.
    step = 0.09,
    weight.upper.bound = 30,
    verbose = F
  )
  
  names(results_list)[i] <- dataset_name
}
```

```{r}

```



```{r}
# Extract RMSE and condition number from results for each cluster and the full dataset
cluster_summary <- data.frame(
  dataset = names(results_list),
  RMSE = sapply(results_list, function(x) x$RMSE),
  condition_number = sapply(results_list, function(x) x$`condition number`)
) %>%
  # Add a column to distinguish full dataset from clusters
  mutate(
    type = ifelse(dataset == "full_dataset", "Full Dataset", "Cluster"),
    sample_size = sapply(clusters, nrow)
  ) %>%
  # Order with full dataset first, then clusters by RMSE
  arrange(type == "Cluster", RMSE)

# Save as CSV for assessment
# write.csv(cluster_summary, here("summaries", "cluster_analysis_summary_full.csv"),
#           row.names = FALSE)
```

```{r}
# Scatter plot showing both metrics -  review what these mean and provide thresholds and information
ggplot(cluster_summary, aes(x = RMSE, y = condition_number, color = dataset)) +
  geom_point(size = 4) +
  geom_text(aes(label = dataset), vjust = -0.5) +
  geom_vline(xintercept = 0.1, color = "red", size = 1) +
  theme_minimal() +
  labs(title = "RMSE vs Condition Number by Cluster",
       x = "RMSE", 
       y = "Condition Number") +
  theme(legend.position = "none")

#Add lines for acceptable
#common to see condition numbers in thousands - 10^10 is unacceptable and program will stop - indicates too many groups.

#If RMSE > 0.1 then increase step and iteration limit or recluster
```

```{r}
# Create comparison plot - reveiw what is considered acceptable
ggplot(cluster_summary, aes(x = reorder(dataset, RMSE), y = RMSE, fill = type)) +
  geom_col() +
  coord_flip() +
  scale_fill_manual(values = c("Full Dataset" = "darkblue", "Cluster" = "lightblue")) +
  theme_minimal() +
  labs(title = "RMSE Comparison: Full Dataset vs Clusters",
       x = "Dataset", y = "RMSE", fill = "Type") +
  geom_text(aes(label = round(RMSE, 3)), hjust = -0.1, size = 3)

#Add lines for acceptable
#Should not be >0.1
```


```{r}
# Apply function and prepare data in one pipeline
output_dm <- extract_class_abundances(results_list) %>%
  # Rename phytoplankton groups for plotting
  rename(cyan = Cyanobacteria, hapt = Haptophytes, 
         GA = Prasinophytes, cryp = Cryptophytes,
         dino = `Dinoflagellates-1`, dict = Dictyophytes, diat = D1) %>%
  # Convert to long format for ggplot
  pivot_longer(cols = c(GA, cryp, diat, dino, hapt, dict, cyan),
               names_to = "group",
               values_to = "chla") %>%
  # Join metadata
  left_join(metadata, by = "sample_id") %>%
  # Create analysis_type column
  mutate(analysis_type = if_else(cluster == "full_dataset", "full_dataset", "clustered"),
         date = ymd(date)) %>%
  # Calculate daily means while preserving cluster and analysis_type
  group_by(date, site_id, depth, group, cluster, analysis_type) %>%
  summarise(chla = round(mean(chla, na.rm = TRUE), 2), .groups = "drop") %>%
  mutate(year = year(date)) %>% 
  # Reorder columns for better viewing
  select(date, year, site_id, depth, cluster, analysis_type, group, chla)

# Check for duplicates
duplicate_check <- output_dm %>%
  group_by(date, site_id, depth, group, cluster, analysis_type) %>%
  summarise(n = n(), .groups = "drop") %>%
  filter(n > 1)

# Display results
if(nrow(duplicate_check) == 0) {
  cat("No duplicates found - data is ready for plotting!\n")
} else {
  cat("Warning: Duplicates still exist:\n")
  print(duplicate_check)
}

# Quick summary of the data
cat("\nData summary:\n")
cat("Date range:", as.character(min(output_dm$date)), "to", as.character(max(output_dm$date)), "\n")
cat("Number of sites:", length(unique(output_dm$site_id)), "\n")
cat("Phytoplankton groups:", paste(unique(output_dm$group), collapse = ", "), "\n")
cat("Analysis types:", paste(unique(output_dm$analysis_type), collapse = ", "), "\n")
cat("Clusters:", paste(unique(output_dm$cluster), collapse = ", "), "\n")
```

```{r}
#Setting groups and colors for plotting.

#Setting color palette for chemtax - needs to be modified when additional groups are added.

npg_distinct_colors <- c(
  "#E64B35",  # diatoms
  "#4DBBD5",  # dictyochophytes
  # "#00A087",  # raphidophytes - turn on if using.
  "#3C5488",  # Dinoflagellates
  "#F39B7F",  # Cryptophyes
  "#8491B4",  # Green Algae
  "#91D1C2",  # Haptophytes
  "#FFC107",  # Cyanobacteria
  "#7E6148",  # Brown
  "#B09C85"   # Light brown
)

scale_fill_npg_distinct <- function(...) {
  ggplot2::scale_fill_manual(values = npg_distinct_colors, ...)
}

#Setting plotting order phytoplankton groups
#Order phytoplankton groups roughly from smallest to largest - create order list
order_chem <- c("cyan", "hapt", "GA", "cryp",
                   "dino", "raph", "dict", "diat")

#Chemtax full data - Specify order of phyto groups for figures
output_dm <- arrange(mutate(output_dm,
                                group = factor(group,
                                levels = order_chem)))

```

```{r}
output_dm %>%
  filter(year == 2019) %>%
  ggplot() +
  geom_area(aes(date, chla, fill = fct_rev(group)),
           stat = "identity", 
           alpha = 1, color = "black", size = 1) +
  scale_fill_npg_distinct() +
  facet_grid(analysis_type ~.) +
  # scale_x_date(limits = as.Date(c("2024-01-01", "2024-12-31")),
  #              expand = c(0, 0),
  #              date_breaks = "months", date_labels = "%b") +
  theme_bw() +
  labs(y = bquote("Phyto. (mg" ~ m^-3*")"),
       fill = "Group") +
  theme(
        legend.position = "right",
        # legend.position = c(1.02, 0.5),
        legend.key.height = unit(0.5, "cm"),
        # legend.text = element_text(size = 25),
        legend.title = element_blank(),
        text = element_text(size = 38), #35
        axis.text = element_text(color = "black"),
        axis.title.x = element_blank())
        # axis.text.y = element_blank())
```



#See if I can CHEMTAX running in R and compare to my excel analysis
#Try steepest decsent in phytoclass and CHEMTAX R package.
#Can I make my own R package based on Excel code?

```{r}
#I think I should export and then upload elsewhere because if I do a full run then I won't want to run through that each time.

#Version control export name. 
#date+v
#matrix_name

write.csv(output_dm, here("outputs", "manu_inputs_100_all_seasons_2025-07-22.csv"))
```

Running 500 iterations took about 35 minutes, but I ran on the full dataset and clusters - could be reduced by not doing full dataset. 

I think an official comparison with CHEMTAX should be done using a similar clustering approach - would take a while if I can't get it going in R, but needed.

Start with just straight up comparison


I need to research why the clustering approach they use is necessary - I used a different one (Swan et al.). 

```{r}
#Trying to run the steepest descent algorithm to also compare with the CHEMTAX results.
#This is a similar method to chemtax, but there is no ratio limits, so ratios are unbounded.
#In the manuscript they develop an R CHEMTAX, but not provided unfortunately. 


# MC <- Matrix_checks(data_matrix, pigment_matrix)
# Snew <- MC$Snew
# Fnew <- MC$Fnew
# SDRes <- Steepest_Desc(Snew, Fnew, num.loops = 1)

#Something didn't work - giving zeros for most class abundances.
```

```{r}
#Uploading example data
# Sm <- phytoclass::Sm
# Fm <- phytoclass::Fm
```

```{r}
#Running on example data 

# MC <- Matrix_checks(Sm, Fm)
# Snew <- MC$Snew
# Fnew <- MC$Fnew
# SDRes <- Steepest_Desc(Snew, Fnew, num.loops = 10)

#Not working - same error as on my data
# plot(SDRes$Figure)

#Method not working even with example data - potentially issue and not maintained/fixed as not main function of package? 
```

