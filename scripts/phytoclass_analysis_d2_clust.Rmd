---
title: "R Notebook"
output: html_notebook
---

```{r}
#Loading packages
library(phytoclass)
library(readxl)
library(dplyr)
library(tidyr)
library(stringr)
library(lubridate)
library(ggplot2)
library(forcats)
library(here)
library(purrr)
library(hakaiApi)

# Source functions
source(here("functions", "functions.R"))
```
---
Download data and wrangling
---
```{r}
# Initialize the client
client <- Client$new()
```
```{r}
#Setting up Query
endpoint <- "/eims/views/output/hplc"
filter <- "site_id=QU39&"
chl_url <- paste0("https://hecate.hakai.org/api", endpoint,"?limit=-1&", filter)
data <- client$get(chl_url)
```

```{r}
#Wrangling the data to prepare it for analysis

#Select the data and pigments that will be analyzed with phytoclass
# rename columns for analysis and drop any rows with NAs
h <- data %>%
  filter(line_out_depth == 5 & site_id == "QU39" & analyzing_lab == "USC") %>%
  # filter(date < "2019-01-01") %>% 
  select(date,
         site_id,
         depth = line_out_depth,
         chl_c3,
         # C12 = chl_c1_c2,
         Per = peri,
         X19but = `_19_but`,
         Fuco = fuco,
         Pra = prasinoxanthin,
         X19hex = `_19_hex`,
         Viol = violaxanthin,
         Allo = alloxanthin,
         Zea = zeaxanthin,
         Lut = lutein,
         Chl_b = chl_b,
         Tchla = all_chl_a) %>% 
  drop_na() %>% 
  # Calculate daily averages across all pigments - need here as can cause errors with clustering
  group_by(date, site_id, depth) %>%
  summarise(across(chl_c3:Tchla, ~ mean(.x, na.rm = TRUE)), .groups = "drop") %>%
  # Add row numbers and create ID after averaging
  group_by(date) %>% 
  mutate(n = row_number()) %>% 
  ungroup() %>% 
  unite(id, c(date, site_id, depth, n), sep = "-", remove = FALSE)   #Create unique id for later joining


h <- as.data.frame(h)

#Setting ID for rownames to associate metadata at later point.
rownames(h) <- h$id

#Creating data matrix for analysis
data_matrix <- h %>% 
  select(chl_c3:Tchla)

#Creating metadata column to join back with data later.
metadata <- h %>% 
  select(id:depth) %>% 
  rename(sample_id = id)
```

```{r}
# Define pigment columns (excluding TChla, date, site_id, depth, n, id)
pigment_cols <- c("Per", "X19but", "Fuco", "Pra", "X19hex", "Allo", "Zea", "Lut", "Chl_b")

# Calculate pigment:TChla ratios and find min/max for each pigment
ratio_bounds <- h %>%
  # Calculate ratios for each pigment
  mutate(across(all_of(pigment_cols), ~ .x / Tchla, .names = "{.col}_ratio")) %>%
  # Select only the ratio columns
  select(ends_with("_ratio")) %>%
  # Pivot to long format for easier processing
  pivot_longer(everything(), names_to = "pigment", values_to = "ratio") %>%
  # Remove "_ratio" suffix from pigment names
  mutate(pigment = str_remove(pigment, "_ratio")) %>%
  # Filter out any infinite, NaN, or negative values
  filter(is.finite(ratio) & ratio >= 0) %>%
  # Calculate min and max for each pigment
  group_by(pigment) %>%
  summarise(
    min_ratio = min(ratio, na.rm = TRUE),
    max_ratio = max(ratio, na.rm = TRUE),
    n_samples = n(),
    .groups = "drop"
  ) %>%
  # Handle zero minimum values - set to small positive value if needed
  mutate(
    min_ratio = ifelse(min_ratio == 0, 0.001, min_ratio),  # or use min_ratio * 0.1 if you prefer relative
    # Optional: Add some buffer to avoid edge effects
    min_ratio_buffered = min_ratio * 0.9,  # 10% buffer below observed min
    max_ratio_buffered = max_ratio * 1.1   # 10% buffer above observed max
  )
```











```{r}
#running functions to extract standardized input matrices for analysis - Set up so everything is correct; however, phytoclass is very finicky and any small discrepancies between pigment or group names will throw it off. Min Max ratios also have a difference threshold, which is build into the error checking.
results <- create_complete_phytoclass_setup("min_lit_d2.csv",
                                            "max_lit_d2.csv")

min_max_matrix <- results$Min_max           # For phytoclass analysis
pigment_matrix <- results$pigment_matrix    # Binary matrix (1/0)
```

```{r}
#Test to see if data works
test <- simulated_annealing(
    S = data_matrix,
    F = pigment_matrix,
    user_defined_min_max = min_max_matrix,
    do_matrix_checks = T,
    niter = 1, #Kept at one for initial analysis - recommended to be 500.
    step = 0.09,
    weight.upper.bound = 30,
    verbose = T
  )

test$`F matrix`
test$Figure
```


```{r}
#Performs recommended pre-analysis clustering to group data with similar pigment ratios

# Get clusters and remove Clust column
clusters <- lapply(Cluster(data_matrix, min_cluster_size = 30)$cluster.list, #14 is default, but seems crazy
                   function(x) { x$Clust <- NULL; x })
#
# # Add the full dataset as the first element so unclustered results can be compared to clustered.
full_data <- data_matrix
full_data$Clust <- NULL  # Remove cluster column if it exists
clusters <- c(list(full_data), clusters)
#
# # Create names for each cluster in list including full dataset
names(clusters) <- c("full_dataset", paste0("clust", seq_along(clusters[-1])))
list2env(clusters, envir = .GlobalEnv)

# Now you have full_dataset, clust1, clust2, clust3, etc. as separate dataframes
```

```{r}
# Create seasonal subsets based on astronomical seasons
# Assumes you have data_matrix (pigments only) and metadata (with sample_id and date)
# create_seasonal_subsets <- function(data_matrix, metadata, sample_id_col = "sample_id", date_col = "date") {
#   
#   # Ensure metadata date column is Date class
#   if(!inherits(metadata[[date_col]], "Date")) {
#     metadata[[date_col]] <- as.Date(metadata[[date_col]])
#   }
#   
#   # Function to determine astronomical season for a given date
#   get_astronomical_season <- function(date) {
#     year <- year(date)
#     month <- month(date)
#     day <- day(date)
#     
#     # Approximate dates for astronomical seasons (Northern Hemisphere)
#     # Spring Equinox: ~March 20-21
#     # Summer Solstice: ~June 20-21  
#     # Autumn Equinox: ~September 22-23
#     # Winter Solstice: ~December 21-22
#     
#     if ((month == 3 & day >= 20) | month %in% c(4, 5) | (month == 6 & day < 21)) {
#       return("spring")
#     } else if ((month == 6 & day >= 21) | month %in% c(7, 8) | (month == 9 & day < 22)) {
#       return("summer") 
#     } else if ((month == 9 & day >= 22) | month %in% c(10, 11) | (month == 12 & day < 21)) {
#       return("autumn")
#     } else {
#       return("winter")
#     }
#   }
#   
#   # Add season classification to metadata
#   metadata$season <- sapply(metadata[[date_col]], get_astronomical_season)
#   
#   # Match data_matrix rownames to metadata sample_id
#   # Assuming rownames(data_matrix) correspond to metadata sample_id
#   sample_seasons <- metadata$season[match(rownames(data_matrix), metadata[[sample_id_col]])]
#   
#   # Create seasonal subsets of data_matrix
#   spring_data <- data_matrix[sample_seasons == "spring" & !is.na(sample_seasons), , drop = FALSE]
#   summer_data <- data_matrix[sample_seasons == "summer" & !is.na(sample_seasons), , drop = FALSE]
#   autumn_data <- data_matrix[sample_seasons == "autumn" & !is.na(sample_seasons), , drop = FALSE]
#   winter_data <- data_matrix[sample_seasons == "winter" & !is.na(sample_seasons), , drop = FALSE]
#   
#   # Create list similar to clustering approach
#   seasons <- list(
#     full_dataset = data_matrix,
#     spring = spring_data,
#     summer = summer_data, 
#     autumn = autumn_data,
#     winter = winter_data
#   )
#   
#   return(seasons)
# }
# 
# # Apply seasonal subsetting
# # Adjust column names to match your actual metadata structure
# seasons <- create_seasonal_subsets(data_matrix, metadata, 
#                                  sample_id_col = "sample_id", 
#                                  date_col = "date")
# 
# # Add to global environment (similar to your clustering approach)
# list2env(seasons, envir = .GlobalEnv)
# 
# # Remove full dataset if desired (similar to your clustering approach)
# seasons[[1]] <- NULL
# 
# # Set seed once for reproducibility  
# set.seed(7683)
# 
# # Run phytoclass analysis on full dataset and all seasons independently
# results_list <- list()
# for(i in seq_along(seasons)) {
#   season_name <- names(seasons)[i]
#   cat("Processing", season_name, "(", i, "of", length(seasons), ")\n")
#   
#   # Check if season has enough data (similar to min_cluster_size)
#   if(nrow(seasons[[i]]) < 14) {
#     cat("Warning:", season_name, "has only", nrow(seasons[[i]]), "samples - consider combining seasons or using full dataset\n")
#     next
#   }
#   
#   results_list[[i]] <- simulated_annealing(
#     S = seasons[[i]], 
#     F = pigment_matrix,
#     user_defined_min_max = min_max_matrix, # You'll want season-specific matrices here eventually
#     do_matrix_checks = T,
#     niter = 500,
#     step = 0.09,
#     weight.upper.bound = 30,
#     verbose = F
#   )
#   
#   names(results_list)[i] <- season_name
# }
# 
# # Remove NULL elements (seasons with insufficient data)
# results_list <- results_list[!sapply(results_list, is.null)]
# 
# # Print summary of seasonal data sizes
# cat("\nSeasonal data summary:\n")
# for(season_name in names(seasons)) {
#   cat(season_name, ":", nrow(seasons[[season_name]]), "samples\n")
# }
```





```{r}
#If turned on, this will remove the full dataset from the list - likely not necessary to analyze the full dataset each time, just useful to assess the effect of running the analysis on the individual clusters.
clusters[[1]] <- NULL
```



```{r}
# Set seed once for reproducibility
set.seed(7683)
# 
# # Run phytoclass analysis on full dataset and all clusters independently
results_list <- list()
for(i in seq_along(clusters)) {
  dataset_name <- names(clusters)[i]
  cat("Processing", dataset_name, "(", i, "of", length(clusters), ")\n")

  results_list[[i]] <- simulated_annealing(
    S = clusters[[i]],
    F = pigment_matrix,
    user_defined_min_max = min_max_matrix,
    do_matrix_checks = T,
    niter = 500, #Kept at one for initial analysis - recommended to be 500.
    step = 0.09,
    weight.upper.bound = 30,
    verbose = F
  )

  names(results_list)[i] <- dataset_name
}
```

```{r}
# Extract RMSE and condition number from results for each cluster and the full dataset
cluster_summary <- data.frame(
  dataset = names(results_list),
  RMSE = sapply(results_list, function(x) x$RMSE),
  condition_number = sapply(results_list, function(x) x$`condition number`)
) %>%
  # Add a column to distinguish full dataset from clusters
  mutate(
    type = ifelse(dataset == "full_dataset", "Full Dataset", "Cluster"),
    sample_size = sapply(clusters, nrow)#clusters
  ) %>%
  # Order with full dataset first, then clusters by RMSE
  arrange(type == "Cluster", RMSE)

# Save as CSV for assessment
write.csv(cluster_summary, here("summaries", "stats_min_lit_d2_cluster.csv"),
          row.names = FALSE)
```

```{r}
# Function to extract F matrix from a single result and add identifier
extract_f_matrix <- function(result, clusters) {
  f_matrix <- result$`F matrix`
  
  # Convert to dataframe and add season identifier
  f_df <- as.data.frame(f_matrix)
  f_df$clusters <- clusters
  f_df$pigment <- rownames(f_matrix)
  
  # Move identifier columns to front
  f_df <- f_df %>%
    select(clusters, pigment, everything())
  
  return(f_df)
}

# Extract F matrices from all results and combine
combined_f_matrices <- map2_dfr(results_list, names(results_list), extract_f_matrix)


# Optional: Pivot to long format for easier analysis/plotting
f_matrices_long <- combined_f_matrices %>%
  pivot_longer(cols = -c(clusters, pigment), 
               names_to = "phyto_group", 
               values_to = "ratio") %>%
  # Remove any rows where ratio might be NA or 0 if desired
  filter(!is.na(ratio) & ratio > 0)

print("Long format sample:")
print(head(f_matrices_long))

# Optional: Create a summary showing which pigments vary most between seasons
pigment_variation <- f_matrices_long %>%
  group_by(pigment, phyto_group) %>%
  summarise(
    min_ratio = min(ratio, na.rm = TRUE),
    max_ratio = max(ratio, na.rm = TRUE),
    ratio_range = round((max_ratio - min_ratio), 2),
    cv = round((sd(ratio, na.rm = TRUE) / mean(ratio, na.rm = TRUE)), 2),
    .groups = "drop"
  ) %>%
  arrange(desc(ratio_range))

write.csv(combined_f_matrices, here("summaries", "out_matrix_min_lit_d2_cluster.csv"),
          row.names = FALSE)

write.csv(pigment_variation, here("summaries", "out_variation_min_lit_d2_cluster.csv"),
          row.names = FALSE)

print("Pigments with highest seasonal variation:")
print(head(pigment_variation, 10))
```





```{r}
# Scatter plot showing both metrics -  review what these mean and provide thresholds and information
ggplot(cluster_summary, aes(x = RMSE, y = condition_number, color = dataset)) +
  geom_point(size = 4) +
  geom_text(aes(label = dataset), vjust = -0.5) +
  geom_vline(xintercept = 0.1, color = "red", size = 1) +
  theme_minimal() +
  labs(title = "RMSE vs Condition Number by Cluster",
       x = "RMSE", 
       y = "Condition Number") +
  theme(legend.position = "none")

#Add lines for acceptable
#common to see condition numbers in thousands - 10^10 is unacceptable and program will stop - indicates too many groups.

#If RMSE > 0.1 then increase step and iteration limit or recluster
```

```{r}
# Create comparison plot - reveiw what is considered acceptable
ggplot(cluster_summary, aes(x = reorder(dataset, RMSE), y = RMSE, fill = type)) +
  geom_col() +
  coord_flip() +
  scale_fill_manual(values = c("Full Dataset" = "darkblue", "Cluster" = "lightblue")) +
  theme_minimal() +
  labs(title = "RMSE Comparison: Full Dataset vs Clusters",
       x = "Dataset", y = "RMSE", fill = "Type") +
  geom_text(aes(label = round(RMSE, 3)), hjust = -0.1, size = 3)

#Add lines for acceptable
#Should not be >0.1
```


```{r}
# Apply function and prepare data in one pipeline
output_dm <- extract_class_abundances(results_list) %>%
  # Rename phytoplankton groups for plotting
  rename(
         cyan = Cyanobacteria,
         hapt = Haptophytes, 
         GA = Prasinophytes,
         cryp = Cryptophytes,
         dino = `Dinoflagellates-1`,
         dict = Dictyophytes,
         # raph = Raphido,
         diat = D1,
         D2 = D2) %>%
  # Convert to long format for ggplot
  pivot_longer(cols = c(GA, cryp, diat, dino, hapt, dict, cyan, D2),
               names_to = "group",
               values_to = "chla") %>%
  # Join metadata
  left_join(metadata, by = "sample_id") %>%
  # Create analysis_type column
  mutate(analysis_type = if_else(cluster == "full_dataset", "full_dataset", "clustered"),
         date = ymd(date)) %>%
  # Calculate daily means while preserving cluster and analysis_type
  group_by(date, site_id, depth, group, cluster, analysis_type) %>%
  summarise(chla = round(mean(chla, na.rm = TRUE), 2), .groups = "drop") %>%
  mutate(year = year(date)) %>% 
  # Reorder columns for better viewing
  select(date, year, site_id, depth, cluster, analysis_type, group, chla)

# Check for duplicates
duplicate_check <- output_dm %>%
  group_by(date, site_id, depth, group, cluster, analysis_type) %>%
  summarise(n = n(), .groups = "drop") %>%
  filter(n > 1)

# Display results
if(nrow(duplicate_check) == 0) {
  cat("No duplicates found - data is ready for plotting!\n")
} else {
  cat("Warning: Duplicates still exist:\n")
  print(duplicate_check)
}

# Quick summary of the data
cat("\nData summary:\n")
cat("Date range:", as.character(min(output_dm$date)), "to", as.character(max(output_dm$date)), "\n")
cat("Number of sites:", length(unique(output_dm$site_id)), "\n")
cat("Phytoplankton groups:", paste(unique(output_dm$group), collapse = ", "), "\n")
cat("Analysis types:", paste(unique(output_dm$analysis_type), collapse = ", "), "\n")
cat("Clusters:", paste(unique(output_dm$cluster), collapse = ", "), "\n")
```

```{r}
#Setting groups and colors for plotting.

#Setting color palette for chemtax - needs to be modified when additional groups are added.

npg_distinct_colors <- c(
  "#E64B35",  # diatoms
  "#4DBBD5",  # dictyochophytes
  "#00A087",  # raphidophytes - turn on if using.
  "#3C5488",  # Dinoflagellates
  "#F39B7F",  # Cryptophyes
  "#8491B4",  # Green Algae
  "#91D1C2",  # Haptophytes
  "#FFC107",  # Cyanobacteria
  "#7E6148",  # Brown
  "#B09C85"   # Light brown
)

scale_fill_npg_distinct <- function(...) {
  ggplot2::scale_fill_manual(values = npg_distinct_colors, ...)
}

#Setting plotting order phytoplankton groups
#Order phytoplankton groups roughly from smallest to largest - create order list
order_chem <- c("cyan", "hapt", "GA", "cryp",
                   "dino", "dict", "raph", "diat", "D2")

#Chemtax full data - Specify order of phyto groups for figures
output_dm <- arrange(mutate(output_dm,
                                group = factor(group,
                                levels = order_chem)))

```

```{r}
output_dm %>%
  filter(year == 2024) %>%
  ggplot() +
  geom_area(aes(date, chla, fill = fct_rev(group)),
           stat =  "identity", 
           alpha = 1, color = "black", size = 1) +
  scale_fill_npg_distinct() +
  facet_grid(analysis_type ~.) +
  # scale_x_date(limits = as.Date(c("2024-01-01", "2024-12-31")),
  #              expand = c(0, 0),
  #              date_breaks = "months", date_labels = "%b") +
  theme_bw() +
  labs(y = bquote("Phyto. (mg" ~ m^-3*")"),
       fill = "Group") +
  theme(
        legend.position = "right",
        # legend.position = c(1.02, 0.5),
        legend.key.height = unit(0.5, "cm"),
        # legend.text = element_text(size = 25),
        legend.title = element_blank(),
        text = element_text(size = 38), #35
        axis.text = element_text(color = "black"),
        axis.title.x = element_blank())
        # axis.text.y = element_blank())
```

```{r}
test <- output_dm %>% 
  filter(group == "cyan")

test2 <- h %>% 
  select(date, Zea)

join <- test %>% 
  full_join(test2)

join %>% 
  ggplot(aes(x = Zea, y = chla)) +
  geom_point()

h %>% 
  mutate(year = year(date),
         month = month(date)) %>% 
  filter(year == 2022 & month %in% c(2, 3)) %>% 
  ggplot(aes(x = date, y = Zea)) +
  geom_line()
```

```{r}

```

#See if I can CHEMTAX running in R and compare to my excel analysis
#Try steepest decsent in phytoclass and CHEMTAX R package.
#Can I make my own R package based on Excel code?

```{r}
#I think I should export and then upload elsewhere because if I do a full run then I won't want to run through that each time.

#Version control export name. 
#date+v
#matrix_name

write.csv(output_dm, here("outputs", "min_lit_raph_diat_fuco_viol.csv"))
```

Running 500 iterations took about 35 minutes, but I ran on the full dataset and clusters - could be reduced by not doing full dataset. 

I think an official comparison with CHEMTAX should be done using a similar clustering approach - would take a while if I can't get it going in R, but needed.

Start with just straight up comparison


I need to research why the clustering approach they use is necessary - I used a different one (Swan et al.). 

```{r}

```


```{r}
#Trying to run the steepest descent algorithm to also compare with the CHEMTAX results.
#This is a similar method to chemtax, but there is no ratio limits, so ratios are unbounded.
#In the manuscript they develop an R CHEMTAX, but not provided unfortunately. 


# MC <- Matrix_checks(data_matrix, pigment_matrix)
# Snew <- MC$Snew
# Fnew <- MC$Fnew
# SDRes <- Steepest_Desc(Snew, Fnew, num.loops = 1)

#Something didn't work - giving zeros for most class abundances.
```

```{r}
#Uploading example data
# Sm <- phytoclass::Sm
# Fm <- phytoclass::Fm
```

```{r}
#Running on example data 

# MC <- Matrix_checks(Sm, Fm)
# Snew <- MC$Snew
# Fnew <- MC$Fnew
# SDRes <- Steepest_Desc(Snew, Fnew, num.loops = 10)

#Not working - same error as on my data
# plot(SDRes$Figure)

#Method not working even with example data - potentially issue and not maintained/fixed as not main function of package? 
```

